{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ZcK5w9NB-tyP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZcK5w9NB-tyP",
    "outputId": "09c9cc6b-9351-4af6-d688-85e5865a5461"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from google.colab import drive\\ndrive.mount('/content/drive/')\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "LH5Yzz82RgYL",
   "metadata": {
    "id": "LH5Yzz82RgYL"
   },
   "outputs": [],
   "source": [
    "#!python main.py --source=iam --transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bixO5miX_Bf5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bixO5miX_Bf5",
    "outputId": "72d11885-5dd4-487d-fa11-0d3f41379f98"
   },
   "outputs": [],
   "source": [
    "#%cd /home/shashank/Desktop/handwritten-text-recognition-master/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "531eea14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "531eea14",
    "outputId": "2df879da-a207-4c55-e9c9-c56dcdb1e10c"
   },
   "outputs": [],
   "source": [
    "# !pip install kaldiio\n",
    "# !pip install stn\n",
    "# !pip install rapidfuzz\n",
    "# !pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2632d453",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2632d453",
    "outputId": "3edf36fd-a0ef-4501-c81a-f9d9a54ad130"
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow_addons\n",
    "import string\n",
    "sub = dict.fromkeys(string.printable[:95], 0)\n",
    "ins = dict.fromkeys(string.printable[:95], 0)\n",
    "delete = dict.fromkeys(string.printable[:95], 0)\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import numpy as np\n",
    "array=np.zeros((len(string.printable[:95]), len(string.printable[:95])))\n",
    "#array =array.astype(np.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae734177",
   "metadata": {
    "id": "ae734177"
   },
   "outputs": [],
   "source": [
    "def alg4(word1,word2):\n",
    "  M=[[float('inf')]*(len(word2)+1) for i in range(len(word1)+1)]\n",
    "          \n",
    "  #filling last row\n",
    "  for i in range(len(word2)+1):\n",
    "    M[len(word1)][i]=len(word2)-i\n",
    "          \n",
    "  #filling last column\n",
    "  for j in range(len(word1)+1):\n",
    "    M[j][len(word2)]=len(word1)-j\n",
    "              \n",
    "  #filling bottom to up manner\n",
    "          \n",
    "  for i in range(len(word1)-1,-1,-1):\n",
    "    for j in range(len(word2)-1,-1,-1):\n",
    "      if word1[i]==word2[j]:\n",
    "        M[i][j]=M[i+1][j+1]\n",
    "      else:\n",
    "        M[i][j]=1+min(M[i+1][j],M[i][j+1],M[i+1][j+1])\n",
    "\n",
    "  x,y=0,0\n",
    "  #print(x,y)\n",
    "  count=0\n",
    "  while x<len(M)-1 and y<len(M[0])-1:\n",
    "    current=M[x][y]\n",
    "    dia=M[x+1][y+1]\n",
    "    right=M[x][y+1]\n",
    "    bottom=M[x+1][y]\n",
    "    if dia<=right and dia<=bottom and dia<=current:\n",
    "      if dia==current-1:\n",
    "        print(\"Substitution-->\",word1[x],\"replaced by\",word2[y])\n",
    "        array[string.printable[:95].find(word1[x]),string.printable[:95].find(word2[y])]=array[string.printable[:95].find(word1[x]),string.printable[:95].find(word2[y])]+1\n",
    "        sub[word1[x]]=sub[word1[x]]+1\n",
    "        count=count+1\n",
    "        x=x+1\n",
    "        y=y+1\n",
    "      else:\n",
    "        print(\"No operation-->\",word1[x])\n",
    "        x=x+1\n",
    "        y=y+1\n",
    "      \n",
    "    elif right<=bottom and right<=current:\n",
    "      print(\"Insertion\",word2[y])\n",
    "      ins[word2[y]]=ins[word2[y]]+1\n",
    "\n",
    "      count=count+1\n",
    "      y=y+1\n",
    "    else:\n",
    "      print(\"Deletion\",word1[x])\n",
    "      delete[word1[x]]=delete[word1[x]]+1\n",
    "      x=x+1\n",
    "      count=count+1\n",
    "  print(\"total operations\",count)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2363a0b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2363a0b",
    "outputId": "3b0b7ed6-8bdf-495e-eaba-898349193044",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: ../data/iam.hdf5\n",
      "output ../output/iam/flor\n",
      "target ../output/iam/flor/checkpoint_weights.hdf5\n",
      "charset: 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \n",
      "Train images: 6161\n",
      "Validation images: 1840\n",
      "Test images: 1861\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1024, 128, 1)]    0         \n",
      "                                                                 \n",
      " patch_extractor (PatchExtra  (None, None, 256)        0         \n",
      " ctor)                                                           \n",
      "                                                                 \n",
      " patch_encoder (PatchEncoder  (None, 513, 768)         592128    \n",
      " )                                                               \n",
      "                                                                 \n",
      " transformer_encoder (Transf  (None, 513, 768)         47248896  \n",
      " ormerEncoder)                                                   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 768)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " mlp_4 (MLP)                 (None, 98)                665954    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,506,978\n",
      "Trainable params: 48,506,978\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Weight count mismatch for layer #2 (named mlp_4 in the current model, dense_9 in the save file). Layer expects 4 weight(s). Received 2 saved weight(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 73>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m model\u001b[38;5;241m.\u001b[39msummary(output_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# get default callbacks and load checkpoint weights file (HDF5) if exists\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_callbacks(logdir\u001b[38;5;241m=\u001b[39moutput_path, checkpoint\u001b[38;5;241m=\u001b[39mtarget_path, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# to calculate total and average time per epoch\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/new trials/CBAM with spatial (copy)/src/network/model.py:261\u001b[0m, in \u001b[0;36mHTRModel.load_checkpoint\u001b[0;34m(self, target)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompile()\n\u001b[0;32m--> 261\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/htr2/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/htr2/lib/python3.8/site-packages/keras/saving/hdf5_format.py:736\u001b[0m, in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, model)\u001b[0m\n\u001b[1;32m    732\u001b[0m   weight_values \u001b[38;5;241m=\u001b[39m preprocess_weights_for_loading(layer, weight_values,\n\u001b[1;32m    733\u001b[0m                                                  original_keras_version,\n\u001b[1;32m    734\u001b[0m                                                  original_backend)\n\u001b[1;32m    735\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(weight_values) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(symbolic_weights):\n\u001b[0;32m--> 736\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    737\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeight count mismatch for layer #\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in the \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    738\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent model, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in the save file). \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    739\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLayer expects \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(symbolic_weights)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m weight(s). Received \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    740\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(weight_values)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m saved weight(s)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    741\u001b[0m   weight_value_tuples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(symbolic_weights, weight_values)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_level_model_weights\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m f:\n",
      "\u001b[0;31mValueError\u001b[0m: Weight count mismatch for layer #2 (named mlp_4 in the current model, dense_9 in the save file). Layer expects 4 weight(s). Received 2 saved weight(s)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "'''\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "if device_name != \"/device:GPU:0\":\n",
    "    raise SystemError(\"GPU device not found\")\n",
    "\n",
    "print(\"Found GPU at: {}\".format(device_name))\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import string\n",
    "\n",
    "# define parameters\n",
    "source = \"iam\"\n",
    "arch = \"flor\"\n",
    "epochs = 1000\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "# define paths\n",
    "source_path = os.path.join(\"..\", \"data\", f\"{source}.hdf5\")\n",
    "output_path = os.path.join(\"..\", \"output\", source, arch)\n",
    "\n",
    "target_path = os.path.join(output_path, \"checkpoint_weights.hdf5\")\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# define input size, number max of chars per line and list of valid chars\n",
    "input_size = (1024, 128, 1)\n",
    "max_text_length = 129\n",
    "charset_base = string.printable[:95]\n",
    "\n",
    "print(\"source:\", source_path)\n",
    "print(\"output\", output_path)\n",
    "print(\"target\", target_path)\n",
    "print(\"charset:\", charset_base)\n",
    "\n",
    "\n",
    "\n",
    "from data.generator import DataGenerator\n",
    "\n",
    "dtgen = DataGenerator(source=source_path,\n",
    "                      batch_size=batch_size,\n",
    "                      charset=charset_base,\n",
    "                      max_text_length=max_text_length)\n",
    "\n",
    "print(f\"Train images: {dtgen.size['train']}\")\n",
    "print(f\"Validation images: {dtgen.size['valid']}\")\n",
    "print(f\"Test images: {dtgen.size['test']}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from network.model import HTRModel\n",
    "\n",
    "# create and compile HTRModel\n",
    "model = HTRModel(architecture=arch,\n",
    "                 input_size=input_size,\n",
    "                 vocab_size=dtgen.tokenizer.vocab_size,\n",
    "                 beam_width=10,\n",
    "                 stop_tolerance=20,\n",
    "                 reduce_tolerance=15)\n",
    "\n",
    "model.compile(learning_rate=0.001)\n",
    "model.summary(output_path, \"summary.txt\")\n",
    "\n",
    "# get default callbacks and load checkpoint weights file (HDF5) if exists\n",
    "model.load_checkpoint(target=target_path)\n",
    "\n",
    "callbacks = model.get_callbacks(logdir=output_path, checkpoint=target_path, verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# to calculate total and average time per epoch\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "h = model.fit(x=dtgen.next_train_batch(),\n",
    "              epochs=epochs,\n",
    "              steps_per_epoch=dtgen.steps['train'],\n",
    "              validation_data=dtgen.next_valid_batch(),\n",
    "              validation_steps=dtgen.steps['valid'],\n",
    "              callbacks=callbacks,\n",
    "              shuffle=True,\n",
    "              verbose=1)\n",
    "\n",
    "total_time = datetime.datetime.now() - start_time\n",
    "\n",
    "loss = h.history['loss']\n",
    "val_loss = h.history['val_loss']\n",
    "\n",
    "min_val_loss = min(val_loss)\n",
    "min_val_loss_i = val_loss.index(min_val_loss)\n",
    "\n",
    "time_epoch = (total_time / len(loss))\n",
    "total_item = (dtgen.size['train'] + dtgen.size['valid'])\n",
    "\n",
    "t_corpus = \"\\n\".join([\n",
    "    f\"Total train images:      {dtgen.size['train']}\",\n",
    "    f\"Total validation images: {dtgen.size['valid']}\",\n",
    "    f\"Batch:                   {dtgen.batch_size}\\n\",\n",
    "    f\"Total time:              {total_time}\",\n",
    "    f\"Time per epoch:          {time_epoch}\",\n",
    "    f\"Time per item:           {time_epoch / total_item}\\n\",\n",
    "    f\"Total epochs:            {len(loss)}\",\n",
    "    f\"Best epoch               {min_val_loss_i + 1}\\n\",\n",
    "    f\"Training loss:           {loss[min_val_loss_i]:.8f}\",\n",
    "    f\"Validation loss:         {min_val_loss:.8f}\"\n",
    "])\n",
    "\n",
    "with open(os.path.join(output_path, \"train.txt\"), \"w\") as lg:\n",
    "    lg.write(t_corpus)\n",
    "    print(t_corpus)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0Axxwe2zY16a",
   "metadata": {
    "id": "0Axxwe2zY16a"
   },
   "outputs": [],
   "source": [
    "    \n",
    "    \n",
    "from data import preproc as pp\n",
    "import cv2\n",
    "#from google.colab.patches import cv2_imshow\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# predict() function will return the predicts with the probabilities\n",
    "predicts, s = model.predict(x=dtgen.next_test_batch(),\n",
    "                            steps=dtgen.steps['test'],\n",
    "                            ctc_decode=True,\n",
    "                            verbose=1)\n",
    "                            \n",
    "print(s)\n",
    "# decode to string\n",
    "predicts = [dtgen.tokenizer.decode(x[0]) for x in predicts]\n",
    "ground_truth = [x.decode() for x in dtgen.dataset['test']['gt']]\n",
    "\n",
    "total_time = datetime.datetime.now() - start_time\n",
    "\n",
    "# mount predict corpus file\n",
    "with open(os.path.join(output_path, \"predict.txt\"), \"w\") as lg:\n",
    "  for pd, gt in zip(predicts, ground_truth):\n",
    "        lg.write(f\"TE_L {gt}\\nTE_P {pd}\\n\")\n",
    "   \n",
    "for i, item in enumerate(dtgen.dataset['test']['dt'][:10]):\n",
    "  print(\"=\" * 1024, \"\\n\")\n",
    "  cv2.imshow('',pp.adjust_to_see(item))\n",
    "  print(ground_truth[i])\n",
    "  print(predicts[i], \"\\n\")\n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "from data import evaluation\n",
    "\n",
    "evaluate = evaluation.ocr_metrics(predicts, ground_truth)\n",
    "\n",
    "e_corpus = \"\\n\".join([\n",
    "    f\"Total test images:    {dtgen.size['test']}\",\n",
    "    f\"Total time:           {total_time}\",\n",
    "    f\"Time per item:        {total_time / dtgen.size['test']}\\n\",\n",
    "    f\"Metrics:\",\n",
    "    f\"Character Error Rate: {evaluate[0]:.8f}\",\n",
    "    f\"Word Error Rate:      {evaluate[1]:.8f}\",\n",
    "    f\"Sequence Error Rate:  {evaluate[2]:.8f}\"\n",
    "])\n",
    "\n",
    "with open(os.path.join(output_path, \"evaluate.txt\"), \"w\") as lg:\n",
    "  lg.write(e_corpus)\n",
    "    \n",
    "    \n",
    "\n",
    "print(\"\\neval=\",evaluate)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424b6b63",
   "metadata": {
    "id": "424b6b63"
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    " #evaluation metrics added\n",
    " \n",
    "  \n",
    "    \n",
    "# Copyright (c) OpenMMLab. All rights reserved.\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "from rapidfuzz import string_metric\n",
    "\n",
    "\n",
    "def cal_true_positive_char(pred, gt):\n",
    "  all_opt = SequenceMatcher(None, pred, gt)\n",
    "  true_positive_char_num = 0\n",
    "  for opt, _, _, s2, e2 in all_opt.get_opcodes():\n",
    "        if opt == 'equal':\n",
    "          true_positive_char_num += (e2 - s2)\n",
    "        else:\n",
    "          pass\n",
    "  return true_positive_char_num\n",
    "\n",
    "\n",
    "def count_matches(pred_texts, gt_texts):\n",
    "    match_res = {\n",
    "        'gt_char_num': 0,\n",
    "        'pred_char_num': 0,\n",
    "        'true_positive_char_num': 0,\n",
    "        'gt_word_num': 0,\n",
    "        'match_word_num': 0,\n",
    "        'match_word_ignore_case': 0,\n",
    "        'match_word_ignore_case_symbol': 0\n",
    "    }\n",
    "    comp = re.compile('[^A-Z^a-z^0-9^\\u4e00-\\u9fa5]')\n",
    "    norm_ed_sum = 0.0\n",
    "    for pred_text, gt_text in zip(pred_texts, gt_texts):\n",
    "        if gt_text == pred_text:\n",
    "            match_res['match_word_num'] += 1\n",
    "        gt_text_lower = gt_text.lower()\n",
    "        pred_text_lower = pred_text.lower()\n",
    "        if gt_text_lower == pred_text_lower:\n",
    "            match_res['match_word_ignore_case'] += 1\n",
    "        gt_text_lower_ignore = comp.sub('', gt_text_lower)\n",
    "        pred_text_lower_ignore = comp.sub('', pred_text_lower)\n",
    "        if gt_text_lower_ignore == pred_text_lower_ignore:\n",
    "            match_res['match_word_ignore_case_symbol'] += 1\n",
    "        match_res['gt_word_num'] += 1\n",
    "\n",
    "        # normalized edit distance\n",
    "        edit_dist = string_metric.levenshtein(pred_text_lower_ignore,\n",
    "                                              gt_text_lower_ignore)\n",
    "        norm_ed = float(edit_dist) / max(1, len(gt_text_lower_ignore),\n",
    "                                         len(pred_text_lower_ignore))\n",
    "        norm_ed_sum += norm_ed\n",
    "\n",
    "        # number to calculate char level recall & precision\n",
    "        match_res['gt_char_num'] += len(gt_text_lower_ignore)\n",
    "        match_res['pred_char_num'] += len(pred_text_lower_ignore)\n",
    "        true_positive_char_num = cal_true_positive_char(\n",
    "            pred_text_lower_ignore, gt_text_lower_ignore)\n",
    "        match_res['true_positive_char_num'] += true_positive_char_num\n",
    "\n",
    "    normalized_edit_distance = norm_ed_sum / max(1, len(gt_texts))\n",
    "    match_res['ned'] = normalized_edit_distance\n",
    "\n",
    "    return match_res\n",
    "\n",
    "\n",
    "def eval_ocr_metric(pred_texts, gt_texts):\n",
    "    \"\"\"Evaluate the text recognition performance with metric: word accuracy and\n",
    "    1-N.E.D. See https://rrc.cvc.uab.es/?ch=14&com=tasks for details.\n",
    "\n",
    "    Args:\n",
    "        pred_texts (list[str]): Text strings of prediction.\n",
    "        gt_texts (list[str]): Text strings of ground truth.\n",
    "\n",
    "    Returns:\n",
    "        eval_res (dict[str: float]): Metric dict for text recognition, include:\n",
    "            - word_acc: Accuracy in word level.\n",
    "            - word_acc_ignore_case: Accuracy in word level, ignore letter case.\n",
    "            - word_acc_ignore_case_symbol: Accuracy in word level, ignore\n",
    "                letter case and symbol. (default metric for\n",
    "                academic evaluation)\n",
    "            - char_recall: Recall in character level, ignore\n",
    "                letter case and symbol.\n",
    "            - char_precision: Precision in character level, ignore\n",
    "                letter case and symbol.\n",
    "            - 1-N.E.D: 1 - normalized_edit_distance.\n",
    "    \"\"\"\n",
    "    assert isinstance(pred_texts, list)\n",
    "    assert isinstance(gt_texts, list)\n",
    "    assert len(pred_texts) == len(gt_texts)\n",
    "\n",
    "    match_res = count_matches(pred_texts, gt_texts)\n",
    "    eps = 1e-8\n",
    "    char_recall = 1.0 * match_res['true_positive_char_num'] / (\n",
    "        eps + match_res['gt_char_num'])\n",
    "    char_precision = 1.0 * match_res['true_positive_char_num'] / (\n",
    "        eps + match_res['pred_char_num'])\n",
    "    word_acc = 1.0 * match_res['match_word_num'] / (\n",
    "        eps + match_res['gt_word_num'])\n",
    "    word_acc_ignore_case = 1.0 * match_res['match_word_ignore_case'] / (\n",
    "        eps + match_res['gt_word_num'])\n",
    "    word_acc_ignore_case_symbol = 1.0 * match_res[\n",
    "        'match_word_ignore_case_symbol'] / (\n",
    "            eps + match_res['gt_word_num'])\n",
    "\n",
    "    eval_res = {}\n",
    "    eval_res['word_acc'] = word_acc\n",
    "    eval_res['word_acc_ignore_case'] = word_acc_ignore_case\n",
    "    eval_res['word_acc_ignore_case_symbol'] = word_acc_ignore_case_symbol\n",
    "    eval_res['char_recall'] = char_recall\n",
    "    eval_res['char_precision'] = char_precision\n",
    "    eval_res['1-N.E.D'] = 1.0 - match_res['ned']\n",
    "\n",
    "    for key, value in eval_res.items():\n",
    "        eval_res[key] = float('{:.4f}'.format(value))\n",
    "    print(\"predicted text:\",pred_texts)\n",
    "    return eval_res\n",
    "    print(e_corpus)\n",
    "    \n",
    "    \n",
    "    \n",
    "evaluate1 = count_matches(predicts, ground_truth) \n",
    "print(\"\\neval1=\",evaluate1)\n",
    "\n",
    "\n",
    "import re\n",
    "  \n",
    "def remove1(string):\n",
    "    pattern = re.compile(r'\\s+')\n",
    "    return re.sub(pattern, '', string)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "import string       \n",
    "for pred_text, gt_text in zip(predicts, ground_truth):        \n",
    "\tseq2 = pred_text\n",
    "\tseq1 = gt_text\n",
    "\tprint(\"pred text:\",seq2)\n",
    "\tprint(\"ground truth:\",seq1)\n",
    "\t#seq1=seq1.translate({ord(c): None for c in string.whitespace})\n",
    "\n",
    "\t#seq2=seq2.translate({ord(c): None for c in string.whitespace})\n",
    "\t#seq1=remove1(seq1)\n",
    "\t#seq2=remove1(seq2)\n",
    "\tprint(\"pred text2:\",seq2)\n",
    "\tprint(\"ground truth2:\",seq1)\n",
    "\talg4(seq1,seq2)\n",
    " \n",
    "print(ins)\n",
    "print(delete)\n",
    "print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eefbee",
   "metadata": {
    "id": "e5eefbee"
   },
   "outputs": [],
   "source": [
    "keymax = max(zip(sub.values(), sub.keys()))[1]\n",
    "keymax\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar(sub.keys(),sub.values())\n",
    "myList = sub.items()\n",
    "myList = sorted(myList) \n",
    "x, y = zip(*myList) \n",
    "#print(x,y)\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23645c8b",
   "metadata": {
    "id": "23645c8b"
   },
   "outputs": [],
   "source": [
    "myList = sub.items()\n",
    "myList = sorted(myList) \n",
    "x, y = zip(*myList) \n",
    "#print(x,y)\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f86a86c",
   "metadata": {
    "id": "2f86a86c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import string\n",
    "len(string.printable[:95])\n",
    "import pandas as pd\n",
    "\n",
    "df_cm = pd.DataFrame(array, index = [i for i in string.printable[:95]],\n",
    "                  columns = [i for i in string.printable[:95]])\n",
    "plt.figure(figsize = (100,100))\n",
    "sn.heatmap(df_cm, annot=True,fmt=\"s\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c345be",
   "metadata": {
    "id": "71c345be"
   },
   "outputs": [],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f503afcd",
   "metadata": {
    "id": "f503afcd"
   },
   "outputs": [],
   "source": [
    "new=array[10:62,10:62]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d619c9e",
   "metadata": {
    "id": "2d619c9e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "plt.figure(figsize = (100,100))\n",
    "#new=new.pivot(string.printable[10:62])\n",
    "df_cm = pd.DataFrame(new, index = [i for i in string.printable[10:62]],\n",
    "                  columns = [i for i in string.printable[10:62]])\n",
    "ax = sn.heatmap(new, annot=True, fmt=\"f\",cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b7a305",
   "metadata": {
    "id": "33b7a305"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "numpy.savetxt(\"original iam flor.txt\", new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d489c84d",
   "metadata": {
    "id": "d489c84d"
   },
   "outputs": [],
   "source": [
    "ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KCaQa7SXUfwK",
   "metadata": {
    "id": "KCaQa7SXUfwK"
   },
   "outputs": [],
   "source": [
    "delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0cb440",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "HTR_notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
